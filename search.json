[{"categories":"项目","content":"PostgreSQL简介 PostgreSQL 是一款高级企业级开源关系数据库，支持 SQL（关系型）和 JSON（非关系型）查询。它是一个高度稳定的数据库管理系统。PostgreSQL 可用作很多 Web、移动、地理空间和分析应用程序的主要数据存储或数据仓库。 MySQL 和 PostgreSQL 都是热门的开源关系数据库。从传统意义上说，我们认为 MySQL 比较易用且速度快，而 PostgreSQL 的功能比较丰富，并且与 Oracle 等商业数据库的兼容性更好。 仓库：https://github.com/CarelTian/database-Impl ","date":"2025-04-10","objectID":"/posts/doc/postgresql/:1:0","tags":"database","title":"PostgreSQL","uri":"/posts/doc/postgresql/"},{"categories":"项目","content":"自定义类型 相比较于Mysql，postgresql可以有自定义类型，更灵活的扩展函数机制。下面的例子中将展示在数据库中新建一个地址类型。并且支持地址类型的索引，自定义比较，格式化输出。下图展示的是BNF 定义格式。一个地址应该由4 部分组成: DetailedUnitRoad, Suburb, State and Postcode，例如 U19/36 Queen Ave, Southgate, AR 7279 由于地址是不定长的，在postadd.source中定义VARIABLE，输入输出函数，对齐方式为int4，这个参数可从官方文档的建议中找到。 CREATE TYPE postaddress ( internallength = VARIABLE, input = postaddress_in, output = postaddress_out, alignment = int4 -- storage = extended 天坑，加了这东西改bug 3个小时 ); 下面是结构体定义，一个tuple字段都保存在data中，我们在结构体定义每个字段长度用于分隔。 typedef struct PostAddress { int32 vl_len_; int32 unit_len; int32 street_len; int32 suburb_len; int32 state_len; int32 postcode_len; int32 original_len; char data[FLEXIBLE_ARRAY_MEMBER]; }PostAddress; 下面的代码是读取和序列号地址，这里使用了按照规则严格匹配的方法，代码冗长较难维护，但是好在通过了全部测试。还有一种方法是使用正则表达式来解析字符串，代码量和可读性都会好很多。 PG_FUNCTION_INFO_V1(postaddress_in); Datum postaddress_in(PG_FUNCTION_ARGS) { char *str = PG_GETARG_CSTRING(0); PostAddress *result; int32 struct_size; char *unit = \"\",*street=\"\",*suburb=\"\",*state=\"\",*postcode=\"\",*original; char *t=NULL; int unit_len, street_len,suburb_len,state_len,postcode_len,original_len; int len = strlen(str); char *value = (char *) palloc(len+1); strcpy(value, str); value[len]='\\0'; original=value; t = strtok(str, \",\"); if(t==NULL ){ ereport(ERROR,errmsg(\"invalid input syntax for type PostAddress: \\\"%s\\\"\",original)); } char *slash = strchr(t, '/'); if(slash==NULL){ if(!check_street(t)) ereport(ERROR,errmsg(\"invalid input syntax for type PostAddress: \\\"%s\\\"\",original)); t=to_lower(t); street=t; }else{ *slash='\\0'; if(!check_unit(t)|| !check_street(slash+1)) ereport(ERROR,errmsg(\"invalid input syntax for type PostAddress: \\\"%s\\\"\",original)); char * s=slash+1; t=to_lower(t); s=to_lower(s); unit=t; street=s; } t = strtok(NULL, \",\"); if(t==NULL){ ereport(ERROR,errmsg(\"invalid input syntax for type PostAddress: \\\"%s\\\"\",original)); } if(!check_suburb(t)){ ereport(ERROR,errmsg(\"invalid input syntax for type PostAddress: \\\"%s\\\"\",original)); } t=to_lower(t+1); //skip space suburb=t; t = strtok(NULL, \"\u003e\"); if(t==NULL || t[0]!=' '){ ereport(ERROR,errmsg(\"invalid input syntax for type PostAddress: \\\"%s\\\"\",original)); } t=t+1; //skip space slash=strchr(t,' '); if(slash==NULL){ ereport(ERROR,errmsg(\"invalid input syntax for type PostAddress: \\\"%s\\\"\",original)); }else{ *slash='\\0'; if(!check_state(t) || !check_postcode(slash+1)) ereport(ERROR,errmsg(\"invalid input syntax for type PostAddress: \\\"%s\\\"\",original)); char * s=slash+1; t=to_lower(t); s=to_lower(s); state=t; postcode=slash+1; } unit_len = strlen(unit); street_len=strlen(street); suburb_len=strlen(suburb); state_len=strlen(state); postcode_len=strlen(postcode); original_len=strlen(original); struct_size = (int32)(offsetof(PostAddress, data) + unit_len+street_len+suburb_len+state_len+postcode_len+original_len); result = (PostAddress *) palloc(struct_size); SET_VARSIZE(result, struct_size); result-\u003eunit_len = unit_len; result-\u003estreet_len = street_len; result-\u003esuburb_len = suburb_len; result-\u003estate_len = state_len; result-\u003epostcode_len = postcode_len; result-\u003eoriginal_len=original_len; int offset = 0; memcpy(result-\u003edata + offset, unit, unit_len); offset += unit_len; memcpy(result-\u003edata + offset, street, street_len); offset += street_len; memcpy(result-\u003edata + offset, suburb, suburb_len); offset += suburb_len; memcpy(result-\u003edata + offset, state, state_len); offset += state_len; memcpy(result-\u003edata + offset, postcode, postcode_len); offset += postcode_len; memcpy(result-\u003edata + offset, original, original_len); offset += postcode_len; PG_RETURN_POINTER(result); } 还实现地址排序比较，索引，获取细分字段（如街道，州，邮编）可参考仓库代码。 ","date":"2025-04-10","objectID":"/posts/doc/postgresql/:2:0","tags":"database","title":"PostgreSQL","uri":"/posts/doc/postgresql/"},{"categories":"项目","content":"多属性线性哈希文件 这个部分与postgresql不相关，只使用C来实现这个功能。 ","date":"2025-04-10","objectID":"/posts/doc/postgresql/:3:0","tags":"database","title":"PostgreSQL","uri":"/posts/doc/postgresql/"},{"categories":"项目","content":"多属性哈希的代码 Bits tupleHash(Reln r, Tuple t) { char buf[MAXBITS+5]; //*** for debug Count nvals = nattrs(r); char **vals = malloc(nvals*sizeof(char *)); assert(vals != NULL); tupleVals(t, vals); Bits *hash = malloc(nvals * sizeof(Bits)); Bits comphash =0; for (int i = 0; i \u003c nvals; i++) { hash[i] = hash_any((unsigned char *)vals[i], strlen(vals[i])); bitsString(hash[i], buf); // printf(\"hash(%s) = %s\\n\", vals[i], buf); } ChVecItem *cv= chvec(r); for(int i=0;i\u003cMAXCHVEC;i++){ int index=cv[i].att; int pos=cv[i].bit; Bits bit= (hash[index] \u003e\u003e pos) \u0026 1; comphash |=(bit \u003c\u003ci); } bitsString(comphash, buf); //printf(\"compHash: %s\\n\",buf); freeVals(vals,nvals); return comphash; } ","date":"2025-04-10","objectID":"/posts/doc/postgresql/:3:1","tags":"database","title":"PostgreSQL","uri":"/posts/doc/postgresql/"},{"categories":"项目","content":"查询（选择和投影） 主要是模拟PostgreSQL的查询方式，数据库输入的每条记录对应于一条tuple，多个tuple存储在page中。每插入一个tuple，取低位的哈希值作为桶的序号插入到对应的page。所以每当查询时，就可以计算查询字符串的哈希来确定对应的桶。对于使用模糊查询，相对应的哈希位使用特殊处理的方式，即扫描所有未知哈希位的桶号。由于tuple在page中是无序连续存储的，所以并不知道具体存在page的位置编号，因此可以全部遍历所有tuple，比较是否与查询字符串匹配。投影就比较简单，知道了数据类型的结构，将存储的字符串转化为字符数组就很容易处理。 ","date":"2025-04-10","objectID":"/posts/doc/postgresql/:3:2","tags":"database","title":"PostgreSQL","uri":"/posts/doc/postgresql/"},{"categories":"项目","content":"线性哈希 除了普通的page，还有溢出页。如果低位哈希值总是停留在少数的几个桶，那么溢出页就会越来越长，导致查询的效率降低，所以引入了分裂的概念。定义page的容量 c = floor(B/R) ≈ 1024/(10*n)，如果n=3, 那么每插入34个记录，就要对桶进行分裂操作，这里需要使用分裂指针表示即将分裂的桶。当sp = 2^d 时，d+1，sp置0。使用非常巧妙的位扩容机制来扩大深度。发生扩容时，sp指向的桶及其溢出页清空，其值保存在临时tuple数组中，然后创建一个新页，也是根据低位哈希将tuple分配在这两个桶中。以此反复，page保存的值会更加分散，能够更快的查询。 ","date":"2025-04-10","objectID":"/posts/doc/postgresql/:3:3","tags":"database","title":"PostgreSQL","uri":"/posts/doc/postgresql/"},{"categories":"项目","content":"背景 这个项目主要是区块链的练手项目，底层中实现了根据椭圆曲线密码学原理转化为base58编码的地址，交易及区块的序列化和反序列化，联盟链的共识协议，数据的持久化，文件的网络传输方法等等。后端使用的是python 3.9, Django 3.2.13，前端使用的是Vue3。其他框架使用较少，本项目主要以造轮子为主。 为什么要做这个项目？最早接触区块链是因为阅读了一本书，O’Reilly 的《programming bitcoin》。讲了如何使用python从底层实现比特币细节。后来我开始思考为什么区块链需要浪费算力挖矿，仔细分析矿工其实做了两件事情，一个是通过寻找一个哈希值证明它获得了区块奖励，另一个就是打包用户的交易保存在区块中。公有链是完全公开透明的，在不可信网络中达成这个目标唯一的方法就是算力竞争，即挖矿。如果有相对柔和的低算力共识算法，那么暴露在公网非常容易受到攻击，因为攻击者成本低了。我的想法是利用区块链的特点，做一个不需要大量算力挖矿的系统，这种方案只适合于联盟链。 为什么需要联盟链？联盟链代表可信度高的几个节点组成的区块链，不对外开放。联盟链可以做很多定制化特性，一个简易的方案就是头部公司只需分配一块服务器保证其正常运行即可，其余时刻并不需要操作和管理，这好像是达成一个契约，只提供服务器做部署，不对内容做更改，所有数据流通过程序自动运转。理想的情况是政府相关部门也能加入节点监管，提高联盟链的可信度。 头部公司和政府部门加入联盟链的动机是什么？我认为有两个好处，一个是通过提供联盟链服务收取交易的手续费，另一个是提升自身品牌信用。在商业活动中，我认为信用的价值比其研发产品的使用价值更大。对于政府部门来说，提供服务同时能够参与监管和审查，我想这也个也满足了需求。 这个项目是短期个人创意想法，是否适用于现实场景还有待研究。 ","date":"2025-03-27","objectID":"/posts/doc/project_consortium/:1:0","tags":"分布式系统","title":"基于联盟链虚拟财产跨平台交易架构","uri":"/posts/doc/project_consortium/"},{"categories":"项目","content":"项目展示 这个系统的逻辑是启动两个进程，一个是django作为后端，另一个是自己编写了Zerg区块链程序作为链端核心。Zerg对外暴露两个端口，其中一个用于不同节点之间通信，例如广播交易，验证区块，共识协议验证等等，另一个端口和本地后端进行通信。使用的是原始TCP短连接的方式，原因是当时技术储备不足，实际应该使用gRPC和http方式更合理。 ","date":"2025-03-27","objectID":"/posts/doc/project_consortium/:2:0","tags":"分布式系统","title":"基于联盟链虚拟财产跨平台交易架构","uri":"/posts/doc/project_consortium/"},{"categories":"项目","content":"工具类 首先我做了一个区块链工具，这个工具可以用来管理节点的公私钥，创建地址，创建交易序列。底层的算法原理和输入输出格式都与比特币一致，我在交易序列化的细节上做了些简易的处理，主要是通过数据结构转成json再转化为字节的形式。 下面是生成公私钥的程序，因为使用联盟链，节点广播必须使用RSA加密和验证通信内容。点击生成公私钥后会生成两个文件，RSA_PIV，RSA_PUB。把PUB发送给其他节点的Key目录下就能启动共识算法中的验证步骤。 下面是生成地址的程序，类似与用户的区块链钱包。助记词只是影响随机数种子，并不能直接计算得到地址和私钥。完整的输入是加盐哈希，时间戳等信息组合得到的，并且这是离线计算，安全性完全可以保证。 下面是生成交易的程序，类似与用户的区块链钱包。这将会把交易信息序列化为一个长串数字，节点可以解析这串数字用于验证交易的合法性。用户的虚拟财产通过节点验证后会产生一个财产ID。如果一个区块链地址拥有这个财产ID，那么就会保存在数据库和区块链文件中。 ","date":"2025-03-27","objectID":"/posts/doc/project_consortium/:2:1","tags":"分布式系统","title":"基于联盟链虚拟财产跨平台交易架构","uri":"/posts/doc/project_consortium/"},{"categories":"项目","content":"Web 下面两张图的界面显示的是用于节点公私钥管理和区块查询。每个虚拟财产都有一个认证节点用于溯源，认证的节点需要对虚拟财产的真实性和有效性负责。第二张图是区块链查询，显示的是已经由至少一个节点确认的交易。由于只是在测试，定义3个交易产出一个区块，当然区块的创建也可以设置时间定时产出。 这张图展示的是作为用户上传虚拟财产的功能，上传后将会把文件保存在节点的Temporary目录。 下面是管理员界面，管理员可以查看文件的合法性，如果点击接受，那么文件就会永久保存并且交易写入到区块。如果拒绝，那么临时文件区就会删除这个文件，同时给用户返回被拒绝的信息。第二张图界面供查看已经审核通过的虚拟财产。 下面的界面为用户交易的广播通道，这段交易十六进制编码存储了发送者地址，接受者地址，虚拟财产ID，发送者数字签名。序列号内容通过“钱包”生成而来。为什么要设计成这样，主要是因为参考了比特币最原始的广播交易网站。基于椭圆曲线密码学原理，离线签署数字签名，证明拥有者的数字财产。服务器节点接收这段代码后，会解码成完整的原始交易对象，首先验证这个地址是否拥有该数字资产，然后验证数字签名是否为此地址，所有的验证通过后则广播给其他节点，并存储在本地。 ","date":"2025-03-27","objectID":"/posts/doc/project_consortium/:2:2","tags":"分布式系统","title":"基于联盟链虚拟财产跨平台交易架构","uri":"/posts/doc/project_consortium/"},{"categories":"项目","content":"持久化 关于系统的持久化主要有两部分，一个是数据库上的存储，一个是区块文件的存储。为了确保后加入的节点能够快速同步到主链上，所以可以通过解析区块文件来填充数据库。在项目中设置了一个主节点，每隔10秒会向所有节点发送一致性检测请求。请求头包含区块文件数量，时间戳，请求体包含区块文件的哈希值。如果节点缺失部分区块文件，主节点会直接发送原始区块文件。目前只实现了基本的传输和检测功能，可优化的地方有很多，例如使用类似于默克尔树的结构，使用2的n次方数量检测合并的区块文件。减小主节点的网络I/O，可以使用对等节点传输文件。 ","date":"2025-03-27","objectID":"/posts/doc/project_consortium/:2:3","tags":"分布式系统","title":"基于联盟链虚拟财产跨平台交易架构","uri":"/posts/doc/project_consortium/"},{"categories":"项目","content":"总结 本人独立完成项目的所有内容，由于开发时间较短，部分功能与设计并不完善。项目的初衷是实现半匿名形式的交易平台，证明财产属权，例如游戏账号交易，各种具备价值的虚拟产品交易。如果交易者发生纠纷，那么平台承担证明者的职能，提供完整的法律证据支持，以解决互联网交易中的信任危机。不足之处在于开发时技术储备不足，没能提供一个类EVM来实现智能合约。至于为什么不做成一个公有链，有两个原因。第一，无挖矿（Pow）的公有链太脆弱极易遭受网络攻击，系统未必稳定运行。第二，没有找到矿工参与的激励机制，因为本质上系统不存在代币，只是现实中虚拟财产的映射。 ","date":"2025-03-27","objectID":"/posts/doc/project_consortium/:3:0","tags":"分布式系统","title":"基于联盟链虚拟财产跨平台交易架构","uri":"/posts/doc/project_consortium/"},{"categories":"项目","content":"1 背景 4年前的时候做区块链项目总喜欢自己造轮子，但是代码基本功不好，为了代码能跑起来删去了大量细节和简化了很多内容。最后只成了一个简单的玩具。我目标是在国内建立一个应用程度高的联盟链平台，在实现目标之前先站在巨人的肩膀上，利用以太坊做链端的部署。 ","date":"2025-03-24","objectID":"/posts/doc/eth/:1:0","tags":"分布式系统","title":"ETH搭建联盟链的方法","uri":"/posts/doc/eth/"},{"categories":"项目","content":"2 步骤 使用git clone拉取eth源码仓库，按照文档步骤编译启动。截止到文档编辑日期，使用的版本为geth version 1.13.12 创建一个新目录，然后创建一个genesis.json文件，具体参数不细说，按照需要配置。 { \"config\": { \"chainId\": 6452, \"homesteadBlock\": 0, \"eip150Block\": 0, \"eip155Block\": 0, \"eip158Block\": 0, \"byzantiumBlock\": 0, \"constantinopleBlock\": 0, \"petersburgBlock\": 0, \"istanbulBlock\": 0, \"berlinBlock\": 0, \"londonBlock\": 0, \"clique\": { \"period\": 15, \"epoch\": 30000 } }, \"difficulty\": \"0x1\", \"gasLimit\": \"0x989680\", \"extradata\": \"0x0000000000000000000000000000000000000000000000000000000000000000ee0b440ff5594029c8260fadccb712cdf021484e0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"alloc\": { \"0xeE0B440Ff5594029C8260FADCcb712CDF021484e\": { \"balance\": \"50000000000000000000\" } } } geth --datadir ./data init genesis.json 初始化节点 geth –datadir ./data –networkid 6452 –port 6452 –nodiscover –http –http.api “eth,net,web3,personal,miner” –mine –miner.etherbase “0xeE0B440Ff5594029C8260FADCcb712CDF021484e” –allow-insecure-unlock –unlock “0xeE0B440Ff5594029C8260FADCcb712CDF021484e” ","date":"2025-03-24","objectID":"/posts/doc/eth/:2:0","tags":"分布式系统","title":"ETH搭建联盟链的方法","uri":"/posts/doc/eth/"},{"categories":"论文阅读","content":"论文链接 Spanner: Google’s Globally-Distributed Database ","date":"2025-02-18","objectID":"/posts/doc/spanner/:0:0","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"1 背景 Spanner 是一种可扩展，分布式数据库，本质上也是一种由多个Paxos状态机组成的分片式数据库。它能实现全局数据拷贝，数据迁移。Spanner的目的是为了管理跨数据中心的复制数据，相比较于Bigtable不能很好的完成复杂且变化的模式的应用。而且将原先key-value存储结构改为半关系型表中。 Spanner具备一些特性，第一能够动态控制管理数据中心，读写延迟，第二提供外部全局一致的读写，基于时间戳全局一致性。 ","date":"2025-02-18","objectID":"/posts/doc/spanner/:1:0","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"2 实现 Spanner的部署被称为universe(宇宙？领域？) 。Spanner 被组织为一组名为zones的集合，每个zone可以类比为Bigtable中的服务器。zone是一个管理部署的单元，正如字面的意思，通常可以用地理位置划分。每个数据中心可以有一个或多个zone来操作添加和删除。 如下图所示，每个zone内部包含一个zonemaster和成百上千个spanserver，前者负责传递数据给spanserver, 而spanserver为客户端提供服务。Universemaster通常用来显示每个zone的信息和调试，placement driver负责自动管理跨zone通信，同时也能控制span server数据移动和更新。 ","date":"2025-02-18","objectID":"/posts/doc/spanner/:2:0","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"2.1 Spanserver 软件架构 Spanner的tablet是一种数据结构，每个spannerserver会包含100到1000个tablet。这里和Bigtable中类似，实现了一个映射 (key:string, timestamp:int64) →string，不同点是spanner为每个数据增加了时间戳，这样更像是一种使用时间戳划分多版本的数据库。Colossus是一个分布式文件系统，保存的是tablet的预写式日志。为了支持复制，tablet上有一个单独Paxos状态机，采用基于时间的领导者租约，默认时长是10秒。Paxos 状态机被用于实现 一致复制的键值映射集合）。每个副本的键值映射状态都存储在其对应的 Tablet 中。写入必须由领导者启动 Paxos 协议，而取则可以直接访问任何的副本的底层 Tablet。 ","date":"2025-02-18","objectID":"/posts/doc/spanner/:2:1","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"2.2 目录和位置 目录作为数据放置的基本单位 所有属于同一目录的数据共享相同的复制配置 当数据在 Paxos 组之间迁移时，它是以目录为单位进行迁移的，如下图所示。 Spanner 可能会移动一个目录，以： 减少某个 Paxos 组的负载（shed load）。 将经常被一起访问的目录放入同一个 Paxos 组（提高访问效率）。 将目录迁移到更靠近其访问者的 Paxos 组（减少访问延迟）。 目录可以在客户端操作进行的同时迁移，且 一个50MB大小的目录通常可以在几秒钟内完成迁移 Movedir 是一个后台任务，用于在 Paxos 组 之间移动 目录。此外，它还负责 添加或移除 Paxos 组中的副本，因为 Spanner 目前尚未支持 Paxos 内部的配置变更。为了避免在大规模数据迁移时 阻塞正在进行的读写操作，Movedir 不会 作为一个单一事务执行，而是首先 注册迁移操作，然后在后台移动数据。当大部分数据迁移完成后，Movedir 通过 一个事务 来 原子性地 迁移剩余的小部分数据，并更新两个 Paxos 组的元数据。 目录是数据放置的最小单位，应用可以指定其 地理复制属性。Spanner 设计了一种 数据放置配置语言 来管理复制配置管理员 负责 控制副本的数量和类型 以及 副本的地理位置，并预定义不同的复制配置应用通过标记数据库或目录，选择合适的复制配置。 例如： 用户 A 的数据可以存储在欧洲的3个副本 中 用户 B 的数据可以存储在北美的5个副本 中 实际上，目录可能会被拆分成多个片段，如果目录增长过大，这些片段可能会被分配到 不同的 Paxos 组（甚至不同的服务器）。因此，Movedir 真正迁移的是片段，而不是整个目录。 ","date":"2025-02-18","objectID":"/posts/doc/spanner/:2:2","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"2.3 数据模型 Spanner 为应用提供了以下关键特性：基于具有模式（schema）的“半关系型”表的数据模型、类 SQL 的查询语言，以及支持跨行操作的通用事务功能。Spanner 要求所有表必须有一个或多个主键列，且这些主键列是有序的。Spanner 选择提供完整的事务支持，允许开发者先使用简单的方式编写具有事务语义的应用，然后在需要时再对性能瓶颈进行针对性优化，而不是在一开始就因为缺少事务而让开发者编写额外的应用层逻辑来保证一致性。 ","date":"2025-02-18","objectID":"/posts/doc/spanner/:2:3","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"2.4 TrueTime TrueTime 是 Google Spanner 数据库中使用的 全局时钟同步系统，用于提供 严格的外部一致性的事务保证，它能提供一个全局统一的时间戳，并且能够量化时间的不确定性。 TrueTime 采用 时间区间而不是单一时间点，使用范围来表示不确定性。它依赖于 Google 的全球数据中心基础设施，结合了 两种物理时钟： GPS 时钟（Global Positioning System）：接收卫星信号，提供全球时间同步。 原子钟（Atomic Clocks）：用于提供高度精准的本地时间 TrueTime 主要用于 全局事务一致性，确保分布式事务满足 外部一致性和线性化。如果事务 T1 在事务 T2 之前提交，那么所有节点都会看到 T1 的更改在 T2 之前生效。即使 T1 和 T2 发生在不同的数据中心，顺序也能保持，通过时间戳排序来实现这一点，事务提交时通过等待机制避免时钟不同步导致的问题。 ","date":"2025-02-18","objectID":"/posts/doc/spanner/:2:4","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"3 并发控制 并发控制是分布式系统所必须的，这学期有门课叫数据库系统实现，用的PostgreSQL也提到了这个概念。接下来主要讲如何利用TrueTime实现外部一致性，无锁只读事务，无阻塞读取。 ","date":"2025-02-18","objectID":"/posts/doc/spanner/:3:0","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"3.1 时间戳管理 Operation Timestamp Discussion Concurrency Control Replica Required Read-Write Transaction § 4.1.2 pessimistic leader Read-Only Transaction § 4.1.4 lock-free leader for timestamp; any for read, subject to § 4.1.3 Snapshot Read, client-provided timestamp — lock-free any, subject to § 4.1.3 Snapshot Read, client-provided bound § 4.1.3 lock-free any, subject to § 4.1.3 如上面的表所示，Spanner支持4种事务。只读事务必须预先声明不会进行任何写入操作；它不仅仅是一个没有写入的读写事务。 在只读事务中，读取操作会在系统选定的时间戳上执行，并且不需要加锁，因此不会阻塞新的写入操作。 只读事务的读取操作可以在任何足够新的副本上执行。快照读取是指在过去某个时间点执行的读取操作，并且不使用锁。 客户端可以指定一个时间戳来进行快照读取，或者提供所需时间戳的过时性上限，由 Spanner 自动选择时间戳。 ","date":"2025-02-18","objectID":"/posts/doc/spanner/:3:1","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"3.1.1 Paxos 领导者租期 Spanner 的 Paxos 实现使用定时租约来使领导者的任期较长（默认 10 秒）一个潜在的领导者会发送请求以获得定时租约投票；当收到法定数量的租约投票后，该领导者便知道自己已获得租约。副本在成功写入时会隐式地延长其租约投票，而领导者会在租约即将到期时请求延长租约投票。Spanner 依赖以下互斥性不变量：对于每个 Paxos 组，每个 Paxos 领导者的租约区间都与其他领导者的租约区间互不重叠。 3.1.2 为读写事务分配时间戳 事务的读写操作使用两阶段锁，Spanner 依赖以下单调性不变量：在每个 Paxos 组内，Spanner 以单调递增的顺序为 Paxos 写入操作分配时间戳，即使是在不同的领导者之间也是如此。Spanner 还强制执行以下外部一致性不变量：如果事务 T2 的开始时间发生在事务 T1 提交之后，则 T2 的提交时间戳必须大于 T1 的提交时间戳。 3.1.3服务读取时间戳 Spanner需要确定所有副本是最新的，以正确处理请求。每个副本会维持一个t_safe表示该时间戳之前的数据是最新的，只有当读取时间戳 t 满足 t ≤ t_safe 时，副本才能满足该读取请求。t_safe由两个值取最小值决定，第一个是Paxos安全时间，第二个是事务管理器（TM）安全时间，由于受到两阶段提交的影响，处理已准备但尚未提交的事务。对于如何计算TM，每个参与者领导者为每个事务 T_i 记录一个“准备”时间戳 s_prepare_i,g，表示该事务 T_i 在 Paxos 组 g 的准备时间。 事务的最终提交时间 s_i 必须大于等于 s_prepare_i,g（即 s_i ≥ s_prepare_i,g）取所有参与者 Paxos 组 g 中，所有处于“已准备”状态事务 T_i 的 s_prepare_i,g 的最小值 min(s_prepare_i,g)-1，那么 \\begin{align} t_{\\text{safe}}^{TM} \u0026= \\min_{i} \\left( s_{\\text{prepare}, i, g} \\right) - 1 \\end{align} 这样可以确保 Spanner 不会读取到那些可能会回滚或未确定的事务状态。 3.1.4 只读事务分配时间戳 只读事务的执行分为两个阶段 1 分配一个时间戳s 2 在 s 时间戳下执行事务的读取操作，这些读取操作作为快照读取执行，并且可以在任何足够最新的副本上完成 ","date":"2025-02-18","objectID":"/posts/doc/spanner/:3:2","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"3.2细节 3.2.1 读写事务 事务的写入不会立即生效，而是缓存在客户端直到提交。如果读取操作时，事务正在执行尚未提交，那么则看不到写入。 在读写事务中使用would-wait避免死锁，读取过程：客户端向 适当 Paxos 组的 leader 副本发送读取请求。leader 副本获取读取锁，并返回最新的数据。在事务仍然活跃的情况下，客户端持续发送 keepalive 消息，防止参与者超时，从而保持事务状态。 事务提交的两阶段提交（2PC）。当客户端完成所有读取，并且缓存了所有写入，它开始两阶段提交。PC客户端选择一个协调者，向所有参与者的 leader 发送 commit 消息其中包括：协调者的身份信息，所有缓存的写入数据。让客户端负责驱动 2PC 过程，避免在广域网络（WAN）中发送两次数据，从而提高效率。 非协调者的提交步骤：先获取写锁。选择一个准备时间戳 s_prepare必须大于该 leader 为先前事务分配的所有时间戳，通过 Paxos 记录 prepare 事务状态，通知协调者自己的 prepare 时间戳。 协调者的提交步骤：协调者 leader先获取写锁，在所有参与者 leader 反馈 prepare 时间戳后，选择整个事务的提交时间戳 s。通过 Paxos 记录提交状态（如果超时等原因导致提交失败，则记录 abort） 提交等待 为了保证外部一致性，协调者 leader 必须等待 TT.after(s)，s 是基于 TT.now().latest 选择的 事务最终提交，等待结束后，协调者 leader 将最终提交时间戳 s 发送给客户端（通知事务已提交），所有参与者 leader（同步最终事务状态。所有参与者 leader 通过 Paxos 记录事务结果，所有副本在相同的时间戳 s 应用写入，并释放锁。 3.2.2 只读事务 只读事务的时间戳分配需要在所有涉及的 Paxos 组之间进行协商，以确保读取数据的一致性。 Spanner 需要为每个只读事务提供一个“范围表达式”，它概括了事务将要读取的键。 只涉及单个 Paxos 组的情况下，Spanner 可以使用 LastTS() 作为 s_read，避免不必要的延迟。涉及多个 Paxos 组的情况下，Spanner 直接使用 TT.now().latest 作为 s_read，避免额外的通信开销，但可能需要等待 t_safe 。 3.2.3 模式变更事务 Spanner 的模式变更事务是一种“非阻塞”版本的事务，相比标准事务，影响范围更小，避免阻塞整个系统。主要有两个特性，并且依赖于TrueTime 未来时间戳提交，模式变更事务的时间戳 t 预先分配在未来，并在准备阶段注册，这样可以确保跨千台服务器的模式变更操作能在最小干扰下完成。 读写操作如何与模式变更事务同步，所有读取和写入操作都会隐式依赖数据库模式，如果某个读写操作的时间戳早于 t，那么它可以正常执行，不受模式变更的影响。如果某个读写操作的时间戳晚于 t，那么它必须阻塞，等待模式变更事务完成 3.2.4 改进 Spanner 中 t_safe和 LastTS()可能会产生阻塞，这里提出了一种方法避免这个问题。 对于事务管理器安全时间的问题，按照键范围存储已准备事务的时间戳。这些信息可以存储在锁表中，因为锁表本身就维护了键范围与锁元数据的映射。读取请求到达时仅需要检查与其冲突的键范围的安全时间。避免无关的数据读取被阻塞，减少不必要的等待。 对于LastTS()（最后提交时间）的局限性，在锁表中维护一个映射，记录每个键范围的提交时间戳。读取请求到达时只需要查询相关键范围的 LastTS()，并基于事务冲突情况分配 s_read。提高读取效率。 对于Paxos 安全时间的局限性，利用领导者租约的“互斥性不变量“，每个 Paxos 领导者维护 MinNextTS(n) 映射。MinNextTS(n) 记录 Paxos 序列号 n 之后的最小可分配时间戳，当某个副本已应用 Paxos 序列号 n，它可以将 t_safe^{Paxos} 推进到 MinNextTS(n) - 1。 对于领导者的 MinNextTS() 推进策略，默认情况下，每个 Paxos 领导者每 8 秒推进 MinNextTS()。在没有已准备事务的情况下，Paxos 组中的健康从节点最多只能落后 8 秒。如果从节点需要更高的 t_safe^{Paxos}，它可以向领导者请求提前推进 MinNextTS() ","date":"2025-02-18","objectID":"/posts/doc/spanner/:3:3","tags":"分布式系统","title":"【论文阅读】Spanner","uri":"/posts/doc/spanner/"},{"categories":"论文阅读","content":"论文链接 ZooKeeper: Wait-free coordination for Internet-scale systems ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:0:0","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"1 背景 大规模的分布式应用需要不同形式的协调机制，第一是最基本的基于配置的协调形式，第二是组成员关系和领导选举机制，第三是锁能实现原子性操作，控制临界区的访问。一种解决方案是将调度机制开发不同的服务，例如部分服务使用队列，部分服务使用领导者机制。ZooKeeper是一种提供API的方法为程序开发者提供原语，通过协调内核能够在不改变服务核心支持新原语。 Zookeeper API实现了一个类似于文件系统的零等待操作对象，除此之外还使用了FIFO客户端提供顺序执行。总之，ZooKeeper与使用阻塞锁原语的系统有很大差别。 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:1:0","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"2 Zookeeper 服务 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:2:0","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"2.1 服务概念 Zookeeper为客户端提供了一组抽象数据节点（znodes)，这些节点使用层次命名空间组织，类似于UNIX的文件系统，/A/B/C表示znode C的路径，除了临时znodes, 其他都可已有子节点。 常规节点：客户端能显示创建和删除 临时节点：客户端可以显示创建和删除，也可以通过会话系统自动创建或删除 在创建znode，客户端可以设置序列号，单调递增。子节点的序列号不小于其父节点。Zookeeper实现了监视机制，无需轮询就能接收变动通知，只表明数据发生变更，不显示具体内容。这个机制是使用session建立的，客户端连接zookeeper会立即建立session，当session关闭则监视也关闭。例如getData(\"/foo\", true)后，/foo被修改了两次，那么就会触发一次监视事件。zookeeper 不仅可以做一般的数据存储，还可以在每个app节点下独立设置一个组员协议。 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:2:1","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"2.2 客户端API create(path, data, flags)：创建路径path的 znode，存储 data[]，并返回新 znode 的名称。flags设置常规还是临时。 delete(path, version): 删除路径名为path的znode,并且可以指定版本号 exists(path, watch)：返回bool值，可以指定是否监视 getData(path, watch)：获取znode的数值，可以指定是否监视 setData(path, data, version):设置数值，并且可以指定版本号 getChildren(path, watch):返回集合，一个znode下的所有子节点 sync(path): 等待所有客户端连接服务器中的挂起操作 所有操作可以同时满足同步或异步API，没有并发使用同步，用并发就异步，客户端能保证回调按顺序执行。每个更新方法都会附带版本号用来检查，设置-1表示不检查版本号。 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:2:2","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"2.3 ZooKeeper 保证 线性化写：所有的更新请求都是可序列化，按照优先级执行 FIFO客户端顺序：同一客户端请求先入先出 ZooKeeper的线性化定义是可以满足一个客户端有多个未完成的操作，也就是说可以选择未完成操作使用特定顺序，也可以使用先入先出。设想的场景当系统中一个节点被选为领导者，需要修改节点大量的配置和通知进程，领导者可以创建名为ready的znode，其他进程只有当这个znode存在时才能使用。如何znode在创建之前领导者宕机了，那么其他节点不会使用这个未完成的配置。 另一个问题可能出现在客户端除了 ZooKeeper 之外还有自己的通信渠道时。例如，假设有两个客户端 A 和 B，它们在 ZooKeeper 中共享一个配置，并通过一个共享的通信渠道进行通信。如果 A 修改了 ZooKeeper 中的共享配置，并通过共享通信渠道告知 B 这个更改，B 期望在重新读取配置时看到这个更改。但是，如果 B 所连接的 ZooKeeper 副本比 A 的稍微落后，它可能无法立即看到新配置。为了更高效地处理这种情况，ZooKeeper 提供了 sync：在读取操作之前执行 sync，相当于进行了一次“慢读取”。sync 会使服务器在处理读取请求之前应用所有待处理的写请求，但不会引入完整写操作的开销。这一原语在概念上类似于 ISIS 系统中的 flush 原语 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:2:3","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"2.4 原语例子 尽管zookeeper是零等待的，依然可以实现高效的阻塞原语。 配置管理：可以利用zookeeper为配置文件创建一个znode，程序启动后观察znode是否出现变动。 同步：有时需要按顺序启动一个主节点，多个工作节点，利用znode来存储主节点信息，包括ip和端口 组成员：成员启动时创建临时znode，出现故障会被自动删除 简单锁：利用锁文件的方法，锁表示为一个znode。客户端获取锁表现为创建一个指定名称的znode，释放锁表现为删除这个znode。但是这种方法会出现羊群效应，多个客户端共同等待一个锁，导致某些客户端一直获取不了。一个解决方案是在申请等待队列中使用递增序号，按顺序获取锁。 读写锁：同样是临时节点，使用递增序号避免线程饥饿。 双栅栏：一种同时启动，同时结束的同步操作。代码如下 public class DoubleBarrier { private final ZooKeeper zk; private final String barrierPath = \"/double_barrier\"; private final int participantCount; public DoubleBarrier(ZooKeeper zk, int participantCount) { this.zk = zk; this.participantCount = participantCount; } public void enter() throws Exception { String nodePath = barrierPath + \"/node_\"; zk.create(nodePath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); while (true) { List\u003cString\u003e children = zk.getChildren(barrierPath, true); if (children.size() == participantCount) { break; } Thread.sleep(100); } System.out.println(\"All processes have entered. Start working!\"); } public void leave() throws Exception { String nodePath = barrierPath + \"/node_\"; zk.delete(nodePath, -1); while (true) { List\u003cString\u003e children = zk.getChildren(barrierPath, true); if (children.isEmpty()) { break; } Thread.sleep(100); } System.out.println(\"All processes have finished. Barrier released!\"); } } ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:2:4","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"3 Zookeeper 应用场景 主要谈及在雅虎的应用服务 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:3:0","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"4 Zookeeper 实现 ZooKeeper 对请求进行预处理，如果请求涉及服务器间的协作，比如写操作，则会启动一个基于原子广播协议的共识机制。这种机制确保所有服务器最终将请求导致的变更同步至完全复制的数据库中，从而维护数据的一致性。如果只读请求，则可以直接从服务器本地的数据库副本中获取数据并形成响应，无需触发复杂的共识过程，这大大提升了读取操作的效率。 备份数据库是保存在内存中，每个znode默认最大保存1MB数据，可以允许改变。为了保证可恢复性，定期将写操作保存到硬盘生成快照。 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:4:0","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"4.1请求处理 由于消息层是原子性的，要保证本地副本不会出现分歧，尽管在某一时刻应用了多个事务。当领导者接收到写请求后，必须要要计算出未来状态，因为可能存在尚未保存在数据库的事务。比如客户端发出setData，版本号与未来的版本号相匹配，那么服务器才会生成对应的setDataTXN，否则只会返回errorTXN。 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:4:1","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"4.2 原子广播 所有更新Zookeeper的请求会转发给领导者，领导者会执行命令并通过Zab广播改变的状态。Zab使用简单的大多数节点一致协议，只要保证多数服务器正确就能正常工作。(2f+1) 为了实现高吞吐量，使用了管道满载，并保证强顺序一致性。领导者的广播按照顺序交付，旧领导者的广播保证在新领导者发送之前交付。Zab的领导者同时也是Zookeeper的领导者，有时事务会在网络重转中执行两次，由于事务幂等性，这是可以接受的。 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:4:2","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"4.3 复制数据库 每个复制体都会在内存中有zookeeper状态的拷贝，当服务崩溃时，会从最近的状态恢复。这里提到了模糊快照的概念，使用DFS遍历znode，将原数据写入磁盘，读写并发可能会导致缺失某些更新。由于事务幂等性，重新回放最近的事务日志即可恢复到最后一致的状态。 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:4:3","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"4.4 客户端服务器交互 服务器在处理写请求会发送和清除相关更新的监视通知，保证通知是顺序的在本地处理。读请求也是在本地处理，携带一个zxid, 表示服务看到的最后一个事务。快速读取的缺点是不能保证读的顺序性，所以实现了Sync原语操作来确保读到是最新的数据。 客户端和服务器建立通信前会检查zxid,如果服务器发现客户端持有最新的zxid，那么就不会建立连接，客户端能保证连接到的是最新数据。 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:4:4","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"论文阅读","content":"5 评价 这篇论文读起来没有其他分布式系统论文那么舒服，因为没有对系统的细节做太多说明。这部分内容需要继续在开源代码里研究。 ","date":"2025-02-12","objectID":"/posts/doc/zookeeper/:5:0","tags":"分布式系统","title":"【论文阅读】ZooKeeper","uri":"/posts/doc/zookeeper/"},{"categories":"随笔","content":"背景 关于这个话题的思考来源于一次意外，放在桌上的饮料不小心被手碰倒了，导致里面的液体流到了桌子上、手机上和裤子上。而昨天放在桌上的一杯牛奶同样也被我不小心碰倒了，连续两次发生的小概率事件让我开始分析事件背后的原因。 ","date":"2025-02-11","objectID":"/posts/doc/risk/:1:0","tags":"哲学","title":"果因论与风险控制","uri":"/posts/doc/risk/"},{"categories":"随笔","content":"小概率事件 可以把手打翻桌上的牛奶这件事看作小概率事件，因为在过去的一年时间里，我有至少上百次把饮料放在桌子靠左的位置，而无一次出现意外。在生活中存在着无数的小概率事件，例如飞机失事，细胞基因突变，切菜切到手指，超市买到坏的鸡蛋。其中有些事件是可控，有些事件是不可控的。 ","date":"2025-02-11","objectID":"/posts/doc/risk/:2:0","tags":"哲学","title":"果因论与风险控制","uri":"/posts/doc/risk/"},{"categories":"随笔","content":"果因论 从小被教育的是关于因果论，有因就有果。这个推理方向是顺向思维，当我们发现做某件事情就可以得到某个结果，于是把它记录下来，形成了一套知识体系。在这个知识体系中，一切变得可解释性，任何事件的发生都有一个确定的诱因，如果解释不了那就是因为认识的不够，具备的信息量不够多。 因果论的崩塌来自于20世纪爱因斯坦和波尔的争论——上帝掷骰子吗。爱因斯坦认为上帝不掷骰子，即世界是确定的，自然规则不可能是随机的，量子世界也是确定的。波尔认为微观量子现象是概率的，世界本质也是概率的。当今的理论来看，波尔的思想被证明正确。假设因果论完备，那么世界上万物的变化和事件都是设计好的，所有的一切从最初的创世以来就已经写好了结局。这个倒是有趣的观点，当人类知道自己的命运是注定的，可以选择积极态度，也可以选择自暴自弃，或者选择不相信，但无论选择哪一种都最终走向了确定的结局。 目前很多复杂的系统是难以解释的，例如摩擦力的摩擦因素从何确定，人工智能产生智能的底层原因是什么。学术界有些把训练人工智能比作炼丹，原因在于训练之前无法得知最终效果怎么样。一个模型复杂的结构，嵌套的层数，数据的质量共同决定了智能“涌现”的结果，然而把其中的任意参数（Dropout）删除10%并不影响最终展现的智能效果，反而展现更强的泛化能力。现在AI的进化，是通过无数次的训练，通过实验分析获取经验，从而逐渐明白不同的模块和处理方法可能会产生什么样的影响。就好比把一块石头放进装满水的瓶子里，水会溢出。你可以说这是再简单不过的道理，也可以说是因为水的氢键是极其稳定的导致难以压缩，分子间的作用力使水分子被挤出了空间。 果因论是一种反向的视角，由结果反推原因。现实世界很难理解，放到量子领域就是观测才会产生一个确定的结果，不观测永远处于概率叠加态。有了这个特性才会出现概率和未知的概念，不是任何事情都是能确定的。一个例子是，黑色的袋子里有两个球，一个白球，一个红球，手伸进去摸出红球的概率是多少。直观的概率是二分之一，但是假如强用因果论解释就是0%或者100%。一个简化版的推理是，两个球在袋子里多次碰撞导致多次变换位置，最终产生的能量恰好满足白球偏左，红球偏右。当开始伸手抓球时，大脑会觉得好玩超过一半的神经细胞产生兴奋，所以控制手先在袋子里将白球和红球调换了位置，这时离手心最近的是红球，离手背最近的是白球。这时感受到有个球位置正适合抓握，于是直接顺势将红球抓起，那么概率就是100%，整个过程从手伸进袋子之前就已经注定。如果用果因论解释，那么表现为具体抓哪个球是真实的概率存在，可能抓红球的概率略大一点，但是在此之前是不可预测的。 ","date":"2025-02-11","objectID":"/posts/doc/risk/:3:0","tags":"哲学","title":"果因论与风险控制","uri":"/posts/doc/risk/"},{"categories":"随笔","content":"现实意义 接下来说说由此带来的启示。 在此之前，手碰倒饮料可以被认为是一种小概率事件，但是连续出现两次可以推出手碰倒饮料的概率增大了。当然也有可能是因为运气不好，触发了概率更小的事件。因为这种概率是不可能量化的，只能根据发生的次数来推测可能的真实概率，那就假设实际的概率是增大的。那么原因是什么呢？通过反向推理，可能是因为最近饮食不均衡导致注意力没有以前集中，桌子左侧的物品比以前更杂乱遮挡视线，左手臂疲惫，控制的不如以前精准，各种奇怪的小概率原因叠加而产生的结果。有的人这时候可能会想，这是一种借口，事件已经发生了再找理由逃避。我认为这种说法未必正确，这里要明确两件事情。第一，这个事件结果是否可以控制为确定的唯一的（暂且把真实概率达到99%以上认为是确定的）。第二，造成这个事件结果的众多原因里是否存在一个主导原因（促成发生的真实概率大于50%）。 ","date":"2025-02-11","objectID":"/posts/doc/risk/:4:0","tags":"哲学","title":"果因论与风险控制","uri":"/posts/doc/risk/"},{"categories":"随笔","content":"风险控制 其实我们可以把各种小概率事件，看成一个独立的，多因素影响的复杂系统。可以假设最坏的情况发生，在此之前能做哪些措施，所谓君子不立危墙之下。对于小概率事件，两种解决方案，第一种看能否杜绝发生，例如把饮料直接喝完，不放在桌子左侧。第二种，不求降低概率，而转向降低危害，例如时刻把笔记本放在远离饮料的位置。 在我的潜意识里面，其实模拟过很多现实中可能发生的最坏情况。比如意外离世，手机丢失，失业。所以在我的世界观里，尽量能避免什么就避免什么，如果实在发生了，最后保底措施是什么。再说一个风险控制的例子，当车停在路边，乘客下车正确的步骤是回头看车后有没有自行车，确认没有再开车门。但是当你骑自行车穿过路边一排停在路边的轿车时，不能把这种意识寄托别人身上。宁愿骑到机动车道，也要留出预判对方车门打开的距离。 再谈降低危害。狗是非常聪明的动物，你会发现狗有时候明知道做这个事情是不对的，但是仍然会铤而走险去做。原因非常简单，获取的利益大于损失。为了偷吃一块肉而挨一顿打，看上去像是划算的买卖。如果图方便带来心理上的愉悦程度大于饮料弄湿桌子、手机的影响，那么不利因素就是可接受的。 ","date":"2025-02-11","objectID":"/posts/doc/risk/:5:0","tags":"哲学","title":"果因论与风险控制","uri":"/posts/doc/risk/"},{"categories":"论文阅读","content":"论文链接 In Search of an Understandable Consensus Algorithm (Extended Version) ","date":"2025-02-07","objectID":"/posts/doc/raft/:0:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"1、背景 共识算法是指能够让一组机器在一起协作并且能够容忍部分机器的故障。过去几十年，Paxos是最主流的共识算法，但是它较难理解，在现实中使用需要考虑到很多复杂的变化。于是提出了一种Raft的共识算法，其用于教学和实现更加简单。经过实验测试，在两个大学中对43个学生进行教学，有33个能够较好的理解并回答关于Raft的问题。 作者介绍了三个特性： 强领导机制：相比于其他共识算法，Raft具有更强领导者角色。意思是在一组机器中，选出一个领带者，所有的日志数据流由这个领导者发送给其他机器 领导选举：Raft使用随机计时器来选举领导，这个方法只是在心跳包机制中引入了一个小改动，能够更简单快速的解决冲突 成员变动：Raft在处理集群成员变动中使用了联合共识的方法，在调整过程中两组不同配置的大多数集群都会重叠，这样能够在配置变动中能够正常运行。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:1:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"2、复制状态机 复制状态机是用来解决分布式系统中故障容错性，通常用来管理领导者选举和保存配置信息，使其在出现领导者宕机也能恢复存活。具体的例子有Chubby和Zookeeper。 如下图所示，client提交信息给Server，通常为leader，leader通过共识模块将数据转发给其他client，确保所有的机器的日志最终都保存了相同的请求和顺序，同时把执行的命令写入各自日志条目。当大多数节点确认后，将其标注为已提交。所有的节点将更改保存到各自的状态机，一旦命令被每个机器完整的复制，将输出结果发送给client。 复制状态极通常用复制日志来实现，每个服务器保存一组包含指令的日志，能够按照顺序执行。同时保证每个状态机执行的顺序和结果是一致的，内容也是相同。 共识算法的任务正是维护这种复制状态机，由以下特性： 安全性：在出现非拜占庭情况（恶意节点），如网络延迟，数据包丢失，重复等异常情况，不返回错误结果。 可用性：服务器之间能互相通信，在经典的五台服务区中可以允许任意2台故障。故障恢复后能重新加入集群。 容错性：不依赖时序，能处理时钟错误和消息延迟 及时性：一般情况，指令在收到大多数集群相应后快速完成，少速慢节点不影响系统性能。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:2:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3、Raft共识算法 中间有大篇幅批判Paxos，就此跳过。 Raft是一个管理复制日志的算法，通过选举领导者来实现数据一致性。当领导者收到来自客户端日志条目，会把日志复制给其他服务器，并告诉其他服务器什么时候可以把日志安全的保存在状态机中。总的来说，就是一个领导者管理整个系统，如果领导者挂了，再由新的服务器重新选举。 Raft可以将问题拆分为以下三个独立的子问题， 领导选举：当领导者发生故障的时候，一个新的领导者需要被选举出来，确保系统的连续性和稳定性 日志复制：领导者必须从客户端接收日志条目然后复制到集群中的其他节点，并强制要求其他节点的日志和自己保持一致。 安全性：通过状态机来保证安全，如果日志进入了状态机，那么其他服务器就不能在同样的日志索引使用相同命令 ","date":"2025-02-07","objectID":"/posts/doc/raft/:3:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3.1 Raft基础概念 raft集群中的服务器在任何时候都包含三种状态，领导者，跟随者，候选者。正常的系统中，有一个领导者，其他跟随者是被动的，不能发起请求，只能被动回应领导者和候选者。领导者负责所有的请求，如果客户端向追随者发起请求则会转发给领导者。跟随者在收不到消息时，变为候选者启动选举，获得多数选票的候选者成为领导者。当领导者宕机，则降级为跟随者。 Raft将时间划分为任意长度的term，每个term开始于选举，选举出领导者管理集群直到任期结束。理论来说领导者只要一切正常，就能够一直继任。Term充当了逻辑始终的作用，序号随着时间递增。由于服务器之间保存的Term周期会不一致，服务器之间会通过交换term信息，小term会被大term覆盖。 Raft服务器之间使用RPC进行通信，仅需要两种类型。RequestVote RPC和AppendEntry RPC，分别用于投票和更新状态机 ","date":"2025-02-07","objectID":"/posts/doc/raft/:3:1","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3.2 领导者选举 Raft使用心跳机制来触发领导者选举。服务启动初始状态为跟随者，跟随者永远是跟随者只要它能一直收到来自领导者和候选者的合法RPC。 追随者在一段时间（选举超时）没有收到消息后，开始发起选举。首先会增加它的周期然后变为竞选状态，然后投自己一票，再调用其他服务器的RequestVote，将一直保持这个状态直到出现， 赢得选举 另一个服务器赢得选举 一段时间没有决出胜负 一个服务器每个周期内只能投一票，先进先出原则，先看到谁的拉票就投谁。如果在投票中收到了领导者消息，观察它Term序号是否比自己的序号大，如果是则认可，如果不是则不予理会。 有种特殊情况，所有的跟随者同时都变成了候选者，选票就会分散，没有赢家。这时就会开启新一轮投票，Raft使用了随机延迟机制，每个服务器的选举会随机延迟（150-300ms），这样就能解决问题。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:3:2","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3.3 日志复制 选出领导者后开始处理客户端请求，每个请求携带一条被复制状态机执行的指令。领导者将指令作为新日志条目追加至日志中，并并行发起附加条目 RPC 给其他服务器复制，当日志条目被安全复制后，领导者将其状态机执行结果返回给客户端，如果跟随者宕机、延迟或网络丢包，领导者也会持续重试 RPC直至所有跟随者存储所有日志条目。（这里论文没说清楚，如果跟随者下线，一直重发太耗费资源了） 日志条目按序编号，包含创建时的任期号及待执行指令。日志条目在满足一定条件时变为可提交状态，即安全地应用到状态机中。领导者决定何时提交日志条目，Raft 算法保证所有提交条目持久化并最终被执行。日志条目在被复制到多数服务器时即被提交，包括前任领导者创建的条目。领导者追踪最大已提交条目索引，并在附加条目 RPC 中包含该索引，使跟随者同步应用已提交条目。通过两种方式保证日志的一致性，一是在一个日志索引对应一个条目，且内容和位置不会更改。二是使用AppendEntry RPC时，领导者会携带之前的条目索引和任期编号，如果跟随者找不到这条索引和任期编号就会拒绝日志条目。 下图展示了一个特殊的情况，a-b丢失了一些日志条目，c-d或者e有多余未提交的条目。f情况特殊，在term2中当选领导者，刚提交到日志就崩溃了，竞选到term3后提交了一些信息又崩溃了。Raft的处理办法是， 当AppendEntries RPC失败，领导者可以强制覆盖跟随者的日志，领导者为每个追随者维护一个尾指针，表示即将写入的位置。如果出现一致性检查失败，尾指针减一，直到和领导者一致，然后会删除冲突条目，追加领导者条目。 文中提出了一个没什么必要的优化方法，发生AppendEntries RPC冲突时，跟随者主动发送这个冲突任期内的第一个条目，直至不冲突，这样减小比对的次数。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:3:3","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3.4 安全性 上面的只谈及领导者选举和添加日志，尚未讨论状态机执行的命令和顺序相同。例如跟随者出现故障导致错过了一些日志，然而又不小心当上了领导者，导致指令执行混乱。接下来会完善机制，保证每个term的新任领导者会拥有之前已提交的完整日志条目。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:4:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3.4.1 选举限制 Raft使用了一个简单的机制，保证领导者在选举阶段必须拥有所有已提交的日志，维护日志条目只能领导者流向跟随者这个原则。候选者选举必须通知集群大多数节点，展示其日志最新条目。投票节点如果发现候选者日志最新消息和自己的相比是旧的，那么可以拒绝执行RequestVote RPC。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:4:1","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3.4.2 提交前任日志条目 领导者任期的日志条目被复制到大多数节点则被认为可提交，但是考虑一种情况，领导者在提交前刚好宕机，但是大多数节点已经复制了这个条目，这时一个没有复制这个条目的服务器当选了领导者，不能通过这条日志被复制的数量来决定是否已经提交。Raft原则是领导者不能从跟随者复制数据，一旦成为领导者就只能复制给别者。所以处理方案是，如果领导者保留了前任的日志条目，可以在当前任期内连同旧日志条目一起提交。 假设任期U（U\u003eT），那么领导者中必定包含T任期内的已提交日志，日志匹配原则保证未来领导者同样也会保留最新日志。一句话总结，拥有最新最长日志条目的服务器拥有更高的优先级。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:4:2","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3.4.3 安全性讨论 这里面有几个关键时间点，只有当领导者复制日志给大多数节点才会触发commit，这个commit索引再转发给其他节点表示已提交。考虑两个特殊情况，一、领导者已经把日志复制到大多数节点但尚未提交就宕机了，那么新来的领导者必然包含这个日志的复制，在任期内使用日志一致性检查再一同提交。二、领导者刚复制到少量节点就宕机了，那么这里再包含两种情况，其一，具有最新日志的少量的节点当选领导者，那么可以继续继承日志没有数据丢失。其二，未包含最新日志的节点当选领导者，那么触发强制覆盖，所有节点会和它保持一致，这样就会导致日志丢失。 目前文中并没有说解决方案，谈此处理结果会增加系统的复杂度，所以允许未提交的日志丢失是可接受的。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:4:3","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3.5 跟随者和候选者宕机 RPC操作是幂等性的，即同一条命令触发多次的结果不变。所以这两个宕机最简单的处理方法就是无限调用RPC直到响应。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:5:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"3.6 时间和可用性 Raft的安全性之一就是不依赖于时钟，执行快慢不会产生错误结果。具体是使用Term序列来表示逻辑时钟。领导者选举时间是最为重要的，要求领导者响应时间要快。保证， \\begin{equation} \\text{Broadcast Time} \\ll \\text{Election Timeout} \\ll \\text{MTBF} \\end{equation} 广播时间在[0.5ms,20ms]，选举时间可以在[10ms,500ms]，故障时间不设限制。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:6:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"4 集群成员变化 目前假设成员配置是固定的，实际上我们需要动态改变配置。这里提出了一个二阶段方案，第一阶段禁用所有旧配置节点，第二阶段切换配置上线，具体使用联合共识方法。 日志条目会备份到两种配置的服务器 任一种配置的服务器都可以做领导者 选举和提交日志必须同时获得旧配置和新配置的多数确认 领导者接收（new）请求，会把它看作是一个日志条目打包成（old, new）进行复制，正常来说可以和日志一样复制到整个集群。如果领导者提交后中途宕机，具有只有同时拥有（old,new）的服务器才能当领导者，新领导者就会把（new）复制给整个集群。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:7:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"5 日志压缩 随着时间增长，日志会越来越大开始占用大量内存，以致会丢弃信息。Raft使用快照来解决这个方案，如下图所示，压缩的快照包含日志条目的数量，种类，最终值。每个服务器自己创建一个独立的快照。有时领导者会直接向跟随者（新加入或落后的跟随者）发送快照，通过调用InstallSnapshotRPC 调用。 作者考虑到另一种方式，弃用AppendEntry RPC，全部使用领导者发送快照的模式。这样做的缺点是太占用网络了。快照一般都比较大，每次发送都会大幅影响I/O速度。而且每个服务器在本地创建快照的开销远小于通过网络发送接收的开销。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:8:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"6 客户端交互 客户端怎样和raft交互？服务器怎样发现领导者？Raft如何保证线性化一致性？ 客户端首次启动会随机选一个服务器连接，如果它不是领导者，则拒绝请求，然后返回一个最新领导者的信息。如果这时候领导者宕机，服务器则表现为超时。 如果客户端发送命令后，领导者宕机，那么会重新再发送一次。每个命令会分配一个唯一序列号。如果状态机检测到重复的命令，那么就不会再执行。假如客户端执行只读命令，有可能会获取到过期数据。例如领导者已经被淘汰了但不自知，而新的领导者已经更新了最新数据。所以领导者在回复消息前会通过心跳包问集群的大多数节点它是不是领导者，再处理客户端的消息。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:9:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"论文阅读","content":"7 实现和评价 作者只用了2000行C++代码（不包括测试）就完成了Raft。在斯坦福大学的分布式系统授课，最终表现的教学效果不错。 Raft是在所有节点可信条件下的共识算法，假如黑客要攻击很简单。首先控制一个节点，伪造多余的日志条目，同时发起投票竞选，这样所有的节点会误认为这个坏节点保存最新的日志条目，从而投票给它。这样就轻易地当选领导者，然后利用领导者的强权直接修改覆盖所有节点日志。现实不太可能发生，因为raft集群用于生产环境下服务提供者，一般不涉及什么机密信息。 ","date":"2025-02-07","objectID":"/posts/doc/raft/:10:0","tags":"分布式系统","title":"【论文阅读】Raft","uri":"/posts/doc/raft/"},{"categories":"随笔","content":" 注意 以下内容为作者在现有知识积累下的预测和推理，仅供个人思考，观点正确性请自行判断。 ","date":"2025-02-05","objectID":"/posts/doc/prediction/:0:0","tags":"预测","title":"互联网未来10年的展望","uri":"/posts/doc/prediction/"},{"categories":"随笔","content":"1 背景 近三年来，人工智能领域迎来了蓬勃发展的新阶段。作为2022年12月首批体验ChatGPT的深度用户，我看到了这场技术革命如何重塑生产力。这场突破性进展正推动全球科研机构加速大模型研发竞赛，计算机视觉、语音交互等多模态应用也呈现加速发展态势。在技术融合创新的浪潮中，人类距离实现通用人工智能（AGI）的愿景似乎已不再遥远 与此同时，以Web3技术为代表的加密货币领域进入新一轮牛市，比特币已经突破了10万美元一枚，创下历史新高。这一现象级增长的核心驱动力来自于群体共识。无论它是否真的能给真实世界带来什么，只要有共识，有群体愿意认可其价值，那么它就是有价值的。但同样的，基于共识的价值体系也暗含脆弱性，如果政策风向、市场信心的出现转变，共识的崩塌就会大幅打击价格。 接下来，将对AI与Web3进行讨论。 ","date":"2025-02-05","objectID":"/posts/doc/prediction/:1:0","tags":"预测","title":"互联网未来10年的展望","uri":"/posts/doc/prediction/"},{"categories":"随笔","content":"2 AI OpenAI o1和DeepSeek R1是基于强化学习实现了大模型思考推理能力，并且还能在思考中自我纠错。这个是实现AGI关键一步，因为人类的智力发展就是通过思考和推理逐渐形成。我认为实现AGI还有几个关键步骤，一是有自我驱动力能够自己提问寻找解答，二是永久训练，能够在推理过程中，自我更新模型参数，三是在学习中自发的形成某种结构，类似于人通过反复训练掌握了技能。现有的Ai训练和运行需要大量的内存，显存，高性能显卡，功耗越来越大，体积越来越大，也许未来生物计算机能有重大突破是个不错的方向。 大模型对生产力的提高是显而易见的，尤其对基础脑力劳动者而言。我不擅长前端开发，过去如果让我做个简单的界面，我会花大量时间查阅文档和教程，反复调试和验证。而现在借助大模型，只要掌握提问的技巧，常见的问题都能得到解决。以互联网行业为例，基础服务提供方在AI的帮助下，只需现有一半的员工就可以完成之前的工作量。因此，我认为未来基础岗位的缩减是必然的。客观来说，科技的进步是推动人类历史发展的重要力量。如果AI能够像预测蛋白质结构那样，改造和创新现有的技术，那么第四次工业革命就已经开始了 ","date":"2025-02-05","objectID":"/posts/doc/prediction/:2:0","tags":"预测","title":"互联网未来10年的展望","uri":"/posts/doc/prediction/"},{"categories":"随笔","content":"3 Web3 我对区块链技术有过研究，其本质就是分布式账本技术。中本聪建立它的背景在2008年金融危机，目的在于创造一个去中心金融体系，解决传统金融体系的信任问题，但如今看来并没有解决这个问题。目前对web3主流开发社区停留在以太坊的项目，例如NFT数字资产，铭文等。这里面鱼龙混杂，粗糙的图片，一段奇怪的音频可以拍卖到几十万美元。我认为真正的价值是可以映射到现实世界的，曾看到国内有把NFT门票用作区块链线下活动的入场券，但是这存在一些问题，由于区块链是完全匿名的，如果注册多个地址一个人就可以购买成百上千张票，从而黄牛就能高价转卖给别人。并且由于完全匿名性，黑灰活动追踪溯源困难。所以目前来看去中心化应用还处于早期探索阶段，并没有被大众广为使用。 ","date":"2025-02-05","objectID":"/posts/doc/prediction/:3:0","tags":"预测","title":"互联网未来10年的展望","uri":"/posts/doc/prediction/"},{"categories":"随笔","content":"4 演化 如果让我选择方向，我会all in 去中心化应用，web3，分布式系统。AI的前景虽然很好，但是这是属于头部企业的蛋糕。算力垄断，技术垄断下创业公司能产出重大突破几乎不可能。而选择分布式应用的理由如下，目前用户的隐私数据包括行为喜好被大型企业收集，在信息即价值的时代会形成强大的垄断市场，出现不正当利益和竞争。我理解的去中心化应用是由社区集群来作为网络服务的提供者和维护者，它们由十个左右独立的组织或个体通过定制化的共识协议连接在一起来为用户提供服务，类似于区块链中的联盟链。这样做的的好处是，整个系统的源代码和算法向用户公开，用户可以选择所需要的服务，而不局限于垄断资本设定的规则协议。 ","date":"2025-02-05","objectID":"/posts/doc/prediction/:4:0","tags":"预测","title":"互联网未来10年的展望","uri":"/posts/doc/prediction/"},{"categories":"随笔","content":"4.1 数字ID与统一信用体系 区块链技术虽然具备去中心化与隐私保护的优势，但也因受不法分子利用而诟病。比特币的市值约为2万亿美元，而全球每年的洗钱金额也被估计为2万亿美元。把区块链技术改造成具备实用性的方案，一个折中的方法能兼顾隐私保护与身份追踪。 具体来说，可以使用个人ID（ID card, Driver License）和人脸识别生成一个临时数字ID。基于这一信息创建的地址包含了其他用户无法追踪但政府部门能够追踪的密码。这一密码可通过与数据库中预留的密钥解密得到用户的真实身份信息。该地址既可以理解为比特币中的地址，也可以被视为互联网中的用户名。借助现有密码学技术，这种方案是可行的。 此外，信用体系的建立在现实中已有不少成功案例，例如蚂蚁信用积分、闲鱼信用等级等。然而，这些系统对用户而言往往缺乏透明性，评分与等级计算方式不为人知。相比之下，Uber 的双向评分机制则更具借鉴意义。在Uber中，司机与乘客可以相互评分，并将评分结果直接展示给每轮服务的使用者。 ","date":"2025-02-05","objectID":"/posts/doc/prediction/:5:0","tags":"预测","title":"互联网未来10年的展望","uri":"/posts/doc/prediction/"},{"categories":"随笔","content":"4.2 C2C 点对点交易（C2C）指的是用户对用户的业务模型，不依赖于第三方机构。当今的点对点服务已有一定的雏形，但本质上仍依赖于平台作为担保方，有的甚至是聊天记录作为口头协议。我认识的不少人曾通过这种方式完成交易。例如，网络上两个素不相识的人，一方发布帖子寻求合租，另一方看到后与之沟通，双方一拍即合，认为彼此已经达成共识，但并没有任何风险保障程序。未来，C2C模式有望发展得更加成熟。两个用户可以通过第三方平台交流，当达成一致意见时签署电子协议。该协议由双方密钥各自加密两次，生成两份副本发送至去中心化网络，并同时提交一定数量的Token作为保证金。在协议完成后，双方可以进行一次互评，以完善信用体系。如果出现纠纷，平台将提供记录和证据链支持，帮助双方解决争议。 ","date":"2025-02-05","objectID":"/posts/doc/prediction/:6:0","tags":"预测","title":"互联网未来10年的展望","uri":"/posts/doc/prediction/"},{"categories":"随笔","content":"4.3 大数据和需求匹配 设想下面一个场景，由于刚刚搬家到新城市你把快递默认地址填错了，直到最后才发现。经过计算，亲自去取成本太高。申请退货重新发货，时间拖的太晚。一个理想的解决方案是，找在那个城市的朋友帮忙转寄过来。但问题是，如果没有呢？ 一种有效的解决方案是需求匹配，这在当前已有成功的案例可循。例如，在外卖服务中，用户下单后，信息同步至商家和平台。平台根据地理位置、订单地址、报酬以及完成时限等要素，将订单推送给外卖员供其选择。这个模式可以进一步扩展到更多领域，例如快递代寄、临时杂务等。在理想的场景中，用户可以直接发布需求，设定赏金，并将信息发送至一个去中心化的网络。通过相关性匹配算法，这些需求能够精准推送给适合的人群。此外，为了确保系统的高效与安全，可以借助ai自动化判断需求的合法性、出价的合理性，并实现更细粒度的智能匹配。 ","date":"2025-02-05","objectID":"/posts/doc/prediction/:7:0","tags":"预测","title":"互联网未来10年的展望","uri":"/posts/doc/prediction/"},{"categories":"论文阅读","content":"1 论文链接 https://arxiv.org/abs/1706.03762 ","date":"2024-04-18","objectID":"/posts/doc/transformer/:1:0","tags":"transformer","title":"【论文阅读】Attention Is All You Need","uri":"/posts/doc/transformer/"},{"categories":"论文阅读","content":"2 简介 早期普遍使用RNN来处理翻译任务，它是把输入和输出序列化为token，然后对每个token逐步计算。输入为上一轮计算的状态和当前的输入token，输出为下一轮的状态和输出token。所谓token就是一个单词或一个分词，起始符，终止符等组成，然后映射到一个具体的数值表中。这个结构的输入和输出也被称为编码器-解码器架构。 RNN的主要问题在于编码器和解码器中间通过一个状态传递信息，在处理长序列问题中计算效率和表现不太行，而且必须串行执行，效率低。于是，作者提出了基于注意力机制Transformer架构。它能够并行化训练，在8块P100训练12小时就能取得不错的效果。 ","date":"2024-04-18","objectID":"/posts/doc/transformer/:2:0","tags":"transformer","title":"【论文阅读】Attention Is All You Need","uri":"/posts/doc/transformer/"},{"categories":"论文阅读","content":"3 模型结构 编码器由6个相同的层组成，图中仅展示了一个子层，每个子层中第一个是多头注意力机制捕捉不同位置之间的全局依赖关，第二个是全连接前馈神经网络主要用于非线性变换和特征提取。两个子层都使用了 层归一化和残差连接来保持梯度稳定并提升训练效率，可能是为了在深层网络中保持有效梯度传递和加速收敛。全连接层的作用是为了低维数据(512)扩展到高维（2048）输出。 ","date":"2024-04-18","objectID":"/posts/doc/transformer/:3:0","tags":"transformer","title":"【论文阅读】Attention Is All You Need","uri":"/posts/doc/transformer/"},{"categories":"论文阅读","content":"3.1 嵌入层 图中的embedding layer来源过程如下，句子-\u003etoken化-\u003etoken ID-\u003e嵌入层（d=512)，这样一个词就由一个512维的稠密向量，例如[1.212, 3.234, 5.111, …]所对应的表示“我”。这样一段句子本质上就是一个嵌入矩阵作为输入。Positional Encoding是为了捕捉单词之间的顺序关系，计算公式如下，pos是位置，i是嵌入向量的索引，d=512。 \\begin{align} PE_{(pos, 2i)} \u0026= \\sin \\left( \\frac{pos}{10000^{\\frac{2i}{d}}} \\right) \\ PE_{(pos, 2i+1)} \u0026= \\cos \\left( \\frac{pos}{10000^{\\frac{2i}{d}}} \\right) \\end{align} ","date":"2024-04-18","objectID":"/posts/doc/transformer/:3:1","tags":"transformer","title":"【论文阅读】Attention Is All You Need","uri":"/posts/doc/transformer/"},{"categories":"论文阅读","content":"3.2 多头注意力 文中的多头注意力是由8个缩放点乘积注意力合并得到的，先说缩放点积注意力。Q,K,V是一组抽象的概念，Q直观说就是生成的方向，K用于输入信息匹配，QK内积得到当前位置哪个输出信息最相关，一轮计算得到两个内容，注意力输出表示全局上下文重要信息，权重表示查询位置Q对K的重要程度。 \\begin{align} \\text{Attention}(Q, K, V) \u0026= \\text{softmax} \\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) V \\end{align} ","date":"2024-04-18","objectID":"/posts/doc/transformer/:3:2","tags":"transformer","title":"【论文阅读】Attention Is All You Need","uri":"/posts/doc/transformer/"},{"categories":"论文阅读","content":"3.3 前馈神经网络 扩大维度至2048，捕捉更复杂的特征。Relu将函数变为非线形运算是精髓，是产生智能学习质变的关键之一。 \\begin{align} FFN(x) \u0026= \\max(0, x W_1 + b_1) W_2 + b_2 \\end{align} ","date":"2024-04-18","objectID":"/posts/doc/transformer/:3:3","tags":"transformer","title":"【论文阅读】Attention Is All You Need","uri":"/posts/doc/transformer/"},{"categories":"论文阅读","content":"3.4 注意力在模型中的应用 文中用自注意力层和循环层，卷积层做比较，都是把一个向量映射到另一个向量，比如隐藏层在编码器和解码器之间的作用。通过对计算复杂度，并行化，最长路径网络的比较，自注意力的时间复杂度明显是比其余两者更低的。 Tranformer运用多头注意力在下面三个方面 在编码器-解码器层中，Q来自于上一个解码层的输出，而K,V来源于上一个解码层输出。这样使得解码器的每个位置都能获取输入序列的所有位置。 编码器中的自注意力层，所有的Q，K，V来自于相同的来源。编码器中，它们来源于前一层的输出，第一层来源于嵌入层。这样做生成某个位置的单词时可以考虑输入序列的任意位置单词，捕捉长距离依赖关系。 解码器的自注意力层同样能能关注到第一个位置到当前输出位置的信息，为了保证自回归，训练中不能提前知道未来的词，将未来位置的注意力权重设置负无穷，softmax就会输出0的概率。 ","date":"2024-04-18","objectID":"/posts/doc/transformer/:3:4","tags":"transformer","title":"【论文阅读】Attention Is All You Need","uri":"/posts/doc/transformer/"},{"categories":"论文阅读","content":"4 训练 使用了Adam优化器，β1 = 0.9, β2 = 0.98 and ϵ= 10−9和动态学习率算法。 正则化方法，残差连接+每个子层dropout概率0.1+标签平滑处理 ","date":"2024-04-18","objectID":"/posts/doc/transformer/:4:0","tags":"transformer","title":"【论文阅读】Attention Is All You Need","uri":"/posts/doc/transformer/"},{"categories":"论文阅读","content":"5 评价 相比于RNN和CNN最显著的优点就是能够并行化，缩短计算时间，并且能够合适地处理长序列，捕捉上下序列重要信息。我认为他的缺点是必须要提供大量的数据集才能有较理想的效果，个人设备训练时很容易因数据集不足或模型参数少造成过拟合。 ","date":"2024-04-18","objectID":"/posts/doc/transformer/:5:0","tags":"transformer","title":"【论文阅读】Attention Is All You Need","uri":"/posts/doc/transformer/"},{"categories":"论文阅读","content":"论文链接 MapReduce: Simplified Data Processing on Large Clusters ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:0:0","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"1 背景 2004年正处于互联网起步阶段，谷歌公司为了处理大量的元数据（文档、日志、摘要）需要成百上千台机器处理。这时需要设计一个程序，能够让分布在不同位置的机器并行处理分布式的数据，同时要有容错，简化计算的代码。受到Lisp语言中函数式编程的启发，创造了map和reduce两种操作来处理输入数据。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:1:0","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"2 编程模型 整个模型的输入和输出都是Key/Value形式 Map: 一个函数由用户编写，输入为分割后的数据块，计算得到中间结果对key/value，然后分组合并发送给Reduce函数 Reduce：同样为用户编写，接受中间键值对，根据key来合并组成一个更小的集合，然后输出最终结果。 map(String key, String value): // key: document name // value: document contents for each word w in value: EmitIntermediate(w, “1″); reduce(String key, Iterator values): // key: a word // values: a list of counts int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); 下图以一个简单的例子展示词频统计的数据流动过程。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:2:0","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"3 实现 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:3:0","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"3.1 执行概述 下图以不同职能划分的视角解释MapReduce的过程， MapReduce库首先将输入文件拆分为 M 个部分，每个部分通常为 16 MB 到 64 MB（具体大小可通过可选参数由用户控制）。随后，它在 一组集群机器上启动多个程序副本进行处理 其中一个程序主节点，其余的是工作节点，由主节点分配任务。任务包括 M 个 map 任务 和 R 个 reduce 任务。主节点会选择空闲的工作节点，并为其分配 map 或 reduce 任务。 被分配到map任务的工作节点会读取对应输入分片的内容，对输入数据进行解析，将其拆分为 键值对并将每个键/值对传递给用户定义的 Map 函数。Map 函数生成的中间键值对会暂时缓存在内存中。 缓冲的键值对会被定期写入本地磁盘，并通过分区函数划分为 R 个区域。这些缓冲键值对在本地磁盘上的位置会返回给主节点，主节点负责将这些位置信息转发给 reduce 工作节点。 当主节点通知 reduce 工作节点这些位置后，reduce 节点通过远程过程调用从 map 工作节点的本地磁盘读取缓冲数据。当 reduce 节点读取完所有中间数据后，会根据中间键对数据进行排序，以便将相同键的所有数据分组到一起。由于通常许多不同的键会映射到同一个 reduce 任务，因此排序是必要的。如果中间数据量过大，无法全部加载到内存中，则使用外部排序。 reduce 工作节点遍历排序后的中间数据，对于每个遇到的唯一中间键，将该键及其对应的中间值集合传递给用户定义的 Reduce 函数。Reduce 函数的输出会被追加到该 reduce 分区的最终输出文件中。 当所有的 map 任务和 reduce 任务都完成后，主节点唤醒用户程序。此时，用户程序中的 MapReduce 调用返回到用户代码。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:3:1","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"3.2 master数据结构 它存储每一个map和reduce 任务的状态（空闲、工作中或完成)，以及 worker 机器 (非空闲任务的机器) 的标识。 主节点是中间文件区域位置从 map 任务传播到 reduce 任务的桥梁。因此，对于每个完成的 map 任务，主节点会存储该任务生成的 R 个中间文件区域的位置和大小信息。随着 map 任务的完成，主节点持续接收这些位置和大小信息的更新，并将信息逐步推送给正在执行 reduce 任务的工作节点。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:3:2","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"3.3 容错机制 worker故障：master周期性ping每个worker，如果出现没有相应，则被认定为故障 出现故障后，master将故障worker正在执行或已产出的map标记为失效，重新调度分配给其他worker。如果产出的reduce已完成，则被视为有效产出 master故障：周期性将数据结构写入磁盘，以最小化损失。出现故障终止程序，等到新master运行接替此检查点继续运行。 出现故障的语义：由于MapReduce操作是原子性的，可以保证输出的正确性和顺序一致。大多数情况可以忽略这方面问题。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:3:3","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"3.4 存储位置 GFS——多台机器组成的分布式文件系统。将每个文件分钟64MB的块，将多个副本(3份)保存在不同机器中。master在调度的时候会考虑避免网络传输开销，优先在含有map所需文件的机器 执行。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:3:4","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"3.5 支援任务 指的是某些机器由于网络差，磁盘读写故障等原因拖后腿，速度远远其他worker。当执行到最后阶段时，无论这个拖油瓶是否正在运行，直接将任务重新分配给其他worker，取最先完成的输出文件为准。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:3:5","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"4 改进 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:4:0","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"4.1 分区 使用hash(key) mod R分区，能够比较公平的把相同的Key分到同一个区，并且解决负载均衡问题。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:4:1","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"4.2 排序 每个分区内保证是根据Key来排序的，这有利于在最终输出文件时支持随机访问。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:4:2","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"论文阅读","content":"4.3 Combiner 函数 一种提高I/O效率的方法，在本地将中间结果合并后再转发给Reduce，减小网络传输压力和磁盘读写压力。 ","date":"2024-02-18","objectID":"/posts/doc/mapreduce/:4:3","tags":"分布式系统","title":"【论文阅读】MapReduce","uri":"/posts/doc/mapreduce/"},{"categories":"笔记","content":"Robot Framework简介 RPA框架是机器人过程自动化(RPA)的开源库和工具的集合，它被设计为与Robot Framework和Python一起使用。目标是为软件机器人开发人员提供良好的文档和积极维护的核心库。相比较于纯python实现，它的使用逻辑清晰，使用方法简单，可扩展性高。但是在某些特殊场景，Robot Framework具有局限性，比如并发执行，直接接管浏览器而不需要重新打开。 以下Robot Framework简称RF。RF的应用分为两种，一个是为公司解放劳动力，自动化处理简单但又繁琐的操作。二是为个人使用，现电商抢购活动还有秒杀抢单我认为完全可以用RF实现的。 ","date":"2023-04-10","objectID":"/posts/doc/rf/:1:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"RF准备工作 ","date":"2023-04-10","objectID":"/posts/doc/rf/:2:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"环境 项目 版本 python 3.7.9 rpaframework 22.2.3 robotframework 5.0.1 selenium 4.5.0 ","date":"2023-04-10","objectID":"/posts/doc/rf/:3:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"开发工具 RF实体是一个.robot文件，pycharm的插件有点问题，而且不能识别里面的Keyword。因此使用Vscode进行开发。 需要准备的插件如下所示 ","date":"2023-04-10","objectID":"/posts/doc/rf/:4:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"RF结构 RF分为四部分Settings, Variables, Test Cases, Keywords ","date":"2023-04-10","objectID":"/posts/doc/rf/:5:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"*** Setting *** Documentation 用于机器人的描述和介绍，对执行并没有什么作用 Library 用于导入各种库，每个库会有上百个Keyword Library的官方文档（https://rpaframework.org/index.html） ","date":"2023-04-10","objectID":"/posts/doc/rf/:6:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"*** Variable *** 用于程序初始化的变量 @ 用作创建列表 \u0026 用作创建字典 $ 用作创建字符串或数字 ","date":"2023-04-10","objectID":"/posts/doc/rf/:7:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"*** Test Cases *** 与Task作用一样，用于写总流程 ","date":"2023-04-10","objectID":"/posts/doc/rf/:8:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"***Keywords *** 由多个自定义的Keyword组成，表示执行的步骤。 定义的Keyword下行加[Arguments] ${} 可作为函数的参数。 循环表示方法 FOR ${} IN @{} do something ${} END 判断表示方法 IF condititon do() ELSE IF condition do() ELSE do() END 异常处理 TRY Some Keyword EXCEPT ValueError: * type=GLOB AS ${error} Error Handler 1 ${error} EXCEPT [Ee]rror \\\\d+ (Invalid|Bad) usage type=REGEXP AS ${error} Error Handler 2 ${error} EXCEPT AS ${error} Error Handler 3 ${error} END ","date":"2023-04-10","objectID":"/posts/doc/rf/:9:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"Python扩展 导入库时使用的测试库的名称与实现它的模块或类的名称相同。 ","date":"2023-04-10","objectID":"/posts/doc/rf/:10:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"Library from robot.api.deco import library RF导入python的库就像直接实例化一个类，运行构造参数，如下图所示。 @library装饰器 配置实现为类的库的一种简单方法是使用robot.api.deco.library类装饰器。它允许配置库的作用域、版本、自定义参数转换器、文档格式和监听器，可选参数scope、version、converter、doc_format和监听器。当使用这些参数时，它们会自动设置匹配的ROBOT_LIBRARY_SCOPE、ROBOT_LIBRARY_VERSION、ROBOT_LIBRARY_CONVERTERS、ROBOT_LIBRARY_DOC_FORMAT和ROBOT_LIBRARY_LISTENER属性 ","date":"2023-04-10","objectID":"/posts/doc/rf/:11:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"Keyword from robot.api.deco import keyword 默认情况下，一个python类或模块下的所有函数被认为是Keyword。如果在设置中使用下图设置，默认不配置为keyword。函数的前缀可以使用@keyword开启。 或者直接使用@not_keyword禁用RF。 @keyword(name=None,tag=(),type=())-\u003eAny 可以修改把参数放在name里面 ","date":"2023-04-10","objectID":"/posts/doc/rf/:12:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"常用的库 ","date":"2023-04-10","objectID":"/posts/doc/rf/:13:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"RPA.Browswer.Selenium auto_close=${FALSE} //执行完不自动关闭 打开网站 Open Available Browser url 输入内容 Input Text locator text clear=True 下拉框选择 Select From List By Value locator values 单选按钮 Select Radio Button group_name value 点击元素 Click Element locator id:example name:example xpath://div[@id=“example”] css:div#example 直接提交页面的唯一表单 Submit Form 截图 Screenshot locator output 等待元素出现 Wait Until Page Contains Element locator timeout=None ","date":"2023-04-10","objectID":"/posts/doc/rf/:14:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"RPA.Excel.Files 打开excel Open Workbook path 读取返回表格 Read Worksheet As Table name=None header=False start=None 创建excel Create Workbook path fmt=xlsx sheet_name=None 设置表格值 Set Cell Value row column value 获取表格值并返回 Get Cell Value row column name=active sheet ","date":"2023-04-10","objectID":"/posts/doc/rf/:15:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"参考资料 Robot Framework User Guide（http://robotframework.org/robotframework/latest/RobotFrameworkUserGuide.html） RPA Documentation, Training Courses, Certificates | Robocorp(https://robocorp.com/docs) Keyword libraries(https://robocorp.com/docs/libraries) XPATH定位的用法(https://www.cnblogs.com/aiyiless/p/16111340.html) ","date":"2023-04-10","objectID":"/posts/doc/rf/:16:0","tags":"robot","title":"RF学习总结","uri":"/posts/doc/rf/"},{"categories":"笔记","content":"iptables简介 netfilter/iptables（简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。 ","date":"2021-03-01","objectID":"/posts/doc/iptables/:1:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":"笔记","content":"iptables基础 ​ 规则（rules）其实就是网络管理员预定义的条件，规则一般的定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息 包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规 则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的 主要工作就是添加、修改和删除这些规则。 ","date":"2021-03-01","objectID":"/posts/doc/iptables/:2:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":"笔记","content":"iptables命令的管理控制选项 -A 在指定链的末尾添加（append）一条新的规则 -D 删除（delete）指定链中的某一条规则，可以按规则序号和内容删除 -I 在指定链中插入（insert）一条新的规则，默认在第一行添加 -R 修改、替换（replace）指定链中的某一条规则，可以按规则序号和内容替换 -L 列出（list）指定链中所有的规则进行查看 -E 重命名用户定义的链，不改变链本身 -F 清空（flush） -N 新建（new-chain）一条用户自己定义的规则链 -X 删除指定表中用户自定义的规则链（delete-chain） -P 设置指定链的默认策略（policy） -Z 将所有表的所有链的字节和数据包计数器清零 -n 使用数字形式（numeric）显示输出结果 -v 查看规则表详细信息（verbose）的信息 -V 查看版本(version) -h 获取帮助（help） ","date":"2021-03-01","objectID":"/posts/doc/iptables/:3:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":"笔记","content":"防火墙处理数据包的四种方式 ACCEPT 允许数据包通过 DROP 直接丢弃数据包，不给任何回应信息 REJECT 拒绝数据包通过，必要时会给数据发送端一个响应的信息。 LOG在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则 ","date":"2021-03-01","objectID":"/posts/doc/iptables/:4:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":"笔记","content":"iptables 官方文档 https://netfilter.org/ ","date":"2021-03-01","objectID":"/posts/doc/iptables/:5:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":"笔记","content":"屏蔽外网IP 下面介绍一种方法只有国内的IP才能连接服务器，对防火墙建设有参考价值 ","date":"2021-03-01","objectID":"/posts/doc/iptables/:6:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":"笔记","content":"背景 在我刚接触云产品时，使用的是腾讯云赠送的一个月云服务器。这一个月时间里我似乎也没部署过什么项目，就照着书上和网上的资料稍微捣鼓了下Ubuntu，但是没有使用网络服务的。可就在短短一个月内，有次上机检查，就发现cpu占用率99%，接着腾讯云给我发了条消息，说是中了挖矿病毒。查看日志后，来自卢森堡的一个IP成功登录。 后来我在阿里云租了个云服务器，在上面部署了C/S网络通信类的程序。刚开始网络编程功底不熟，没有对各种异常处理，如果没接收到预期格式的数据包就会报错。我使用的是一个很隐蔽的端口，但是经常会收到全球各地的连接，只要对方一发送数据包，服务器执行的程序就会报错退出。 再后来，我写了个网站，日志中经常能看到会有很多来自国外的爬虫进来逛。那么有没有什么方法屏蔽所有国外的连接呢？ ","date":"2021-03-01","objectID":"/posts/doc/iptables/:7:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":"笔记","content":"建立一条规则链 创建一条规则链mylink，加到入站的规则中 iptables -N mylink iptables -A INPUT -j mylink ","date":"2021-03-01","objectID":"/posts/doc/iptables/:8:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":"笔记","content":"获取国内所有的IP 获取所有国内的ip网段，保存到china_ssr.txt文件中 wget -q --timeout=60 -O- 'http://ftp.apnic.net/apnic/stats/apnic/delegated-apnic-latest' | awk -F\\| '/CN\\|ipv4/ { printf(\"%s/%d\\n\", $4, 32-log($5)/log(2)) }' \u003e /root/china_ssr.txt ","date":"2021-03-01","objectID":"/posts/doc/iptables/:9:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":"笔记","content":"shell脚本 观察ip网段，使用的是网络前缀格式，正好满足iptables的命令格式。用vim t跳转到末尾，发现竟然有8600多行国内网段。那么首先排除一个个手动输入命令的可能，于是我写了个脚本。 while read line do iptables -A mylink -s $line -j ACCEPT done \u003c china_ssr.txt 上面的脚本逐行读取文件的内容，然后执行命令。经过测试，发现iptables的优先级是自顶向下的，即当前规则必须是上面规则的子集，不然就无效。现在已经把所有国内IP允许访问，接下来就禁止全网IP。 iptables -A mylink -j DROP 上面这条命令极其危险。一定要放在链的末尾。本人就是输入了这条命令，导致无法连接到云服务器，无奈之下到阿里云回滚两个月前的快照。 ","date":"2021-03-01","objectID":"/posts/doc/iptables/:10:0","tags":"网络安全","title":"iptables屏蔽所有国外IP!网络安全的利器！","uri":"/posts/doc/iptables/"},{"categories":null,"content":"分布式系统技术爱好者，理想主义者 创建这个博客的目的是为了留下思考、学习、想法的记录。人对于过去的感受只存在于记忆，但是记忆会遗忘。所以利用博客归纳和整理，多记录些值得保留的部分。 ","date":"0001-01-01","objectID":"/me/:0:0","tags":null,"title":"","uri":"/me/"}]